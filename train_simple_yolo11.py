#!/usr/bin/env python3
"""
YOLO11n RGB-T Training Script for KAIST dataset with W&B logging and Config file support
"""
import argparse
from ultralytics import YOLO
import yaml
import torch
import os
import wandb
from datetime import datetime

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", type=str, default="yolo11n.pt", help="model path")
    parser.add_argument("--cfg", type=str, default="", help="model config file path (*.yaml)")
    parser.add_argument("--data", type=str, required=True, help="dataset.yaml path")
    parser.add_argument("--epochs", type=int, default=100, help="training epochs")
    parser.add_argument("--batch-size", type=int, default=16, help="batch size")
    parser.add_argument("--imgsz", type=int, default=640, help="image size")
    parser.add_argument("--device", default="0", help="cuda device: 0, 1, 2, 3 or cpu")
    parser.add_argument("--project", default="runs/train", help="project name")
    parser.add_argument("--name", default="yolo11n_kaist", help="experiment name")
    parser.add_argument("--workers", type=int, default=8, help="dataloader workers")
    parser.add_argument("--patience", type=int, default=50, help="early stopping patience")
    parser.add_argument("--resume", type=str, default="", help="resume training from checkpoint")
    parser.add_argument("--save-period", type=int, default=10, help="save model every N epochs")
    
    # W&B arguments (train_simple.py ì°¸ê³ )
    parser.add_argument("--entity", default=None, help="W&B entity")
    parser.add_argument("--wandb-project", default="KAIST-RGBT-YOLO11n", help="W&B project name")
    parser.add_argument("--wandb-name", default=None, help="W&B run name")
    parser.add_argument("--no-wandb", action="store_true", help="disable W&B logging")
    
    args = parser.parse_args()
    
    # Config íŒŒì¼ ê²€ì¦
    if args.cfg:
        if not os.path.exists(args.cfg):
            raise FileNotFoundError(f"âŒ Config íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.cfg}")
        if not args.cfg.endswith(('.yaml', '.yml')):
            raise ValueError(f"âŒ Config íŒŒì¼ì€ YAML í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤: {args.cfg}")
        print(f"ğŸ“„ Config íŒŒì¼ ì‚¬ìš©: {args.cfg}")
        
        # Config íŒŒì¼ ë‚´ìš© ì½ê¸° ë° ê²€ì¦
        try:
            with open(args.cfg, 'r', encoding='utf-8') as f:
                config_data = yaml.safe_load(f)
            print(f"âœ… Config íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(config_data) if config_data else 0}ê°œ ì„¤ì •")
        except Exception as e:
            raise ValueError(f"âŒ Config íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {e}")
    
    # GPU ë””ë°”ì´ìŠ¤ ì„¤ì • ë° í™•ì¸ (ìˆ˜ì •ëœ ë¶€ë¶„)
    gpu_name = "Unknown GPU"
    gpu_memory = 0
    
    if args.device != "cpu":
        if not torch.cuda.is_available():
            print("âŒ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            args.device = "cpu"
        else:
            try:
                gpu_id = int(args.device)
                if gpu_id >= torch.cuda.device_count():
                    print(f"âŒ GPU {gpu_id}ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ GPU: 0-{torch.cuda.device_count()-1}")
                    gpu_id = 0
                    args.device = "0"
                
                # GPU ì •ë³´ë¥¼ ë¨¼ì € ê°€ì ¸ì˜¤ê¸° (CUDA_VISIBLE_DEVICES ì„¤ì • ì „ì—)
                gpu_name = torch.cuda.get_device_name(gpu_id)
                gpu_memory = torch.cuda.get_device_properties(gpu_id).total_memory / 1024**3
                
                # íŠ¹ì • GPU ì„¤ì •
                os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)
                print(f"âœ… GPU {gpu_id} ì‚¬ìš© ì„¤ì • ì™„ë£Œ")
                print(f"   GPU ì´ë¦„: {gpu_name}")
                print(f"   GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB")
                
                # CUDA_VISIBLE_DEVICES ì„¤ì • í›„ì—ëŠ” deviceë¥¼ "0"ìœ¼ë¡œ ë³€ê²½
                args.device = "0"
                
            except ValueError:
                print(f"âŒ ì˜¬ë°”ë¥´ì§€ ì•Šì€ device ê°’: {args.device}. '0', '1', '2', '3' ë˜ëŠ” 'cpu'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
                args.device = "0"
            except Exception as e:
                print(f"âš ï¸  GPU ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
                print("GPU 0ìœ¼ë¡œ ê¸°ë³¸ ì„¤ì •í•©ë‹ˆë‹¤.")
                args.device = "0"
    
    print(f"ğŸš€ ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤: {args.device}")
    
    # W&B ì´ˆê¸°í™” (train_simple.py ìŠ¤íƒ€ì¼)
    wandb_run = None
    if not args.no_wandb:
        try:
            # W&B run name ì„¤ì •
            if args.wandb_name is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                config_suffix = "_custom_cfg" if args.cfg else ""
                args.wandb_name = f"{args.name}{config_suffix}_{timestamp}"
            
            # W&B config ì¤€ë¹„
            wandb_config = {
                "model": args.model,
                "config_file": args.cfg if args.cfg else "default",
                "epochs": args.epochs,
                "batch_size": args.batch_size,
                "image_size": args.imgsz,
                "device": args.device,
                "workers": args.workers,
                "patience": args.patience,
                "optimizer": "AdamW",
                "dataset": "KAIST RGB-T",
                "architecture": "YOLO11n",
                "input_channels": 6,  # RGB-T
                "gpu_name": gpu_name,
                "gpu_memory_gb": gpu_memory,
            }
            
            # Config íŒŒì¼ì´ ìˆìœ¼ë©´ í•´ë‹¹ ì •ë³´ë„ ì¶”ê°€
            if args.cfg:
                wandb_config["custom_config"] = True
                wandb_config["config_path"] = args.cfg
            
            # W&B ì´ˆê¸°í™”
            wandb_run = wandb.init(
                project=args.wandb_project,
                entity=args.entity,
                name=args.wandb_name,
                config=wandb_config,
                tags=["YOLO11n", "RGB-T", "KAIST", "object-detection"] + (["custom-config"] if args.cfg else []),
                notes=f"YOLO11n training on KAIST RGB-T dataset with 6-channel input{' using custom config' if args.cfg else ''}",
                resume="allow"
            )
            print(f"âœ… W&B ì—°ê²° ì™„ë£Œ: {wandb_run.url}")
            
        except Exception as e:
            print(f"âš ï¸  W&B ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("W&B ì—†ì´ í›ˆë ¨ì„ ê³„ì†í•©ë‹ˆë‹¤.")
            wandb_run = None
    else:
        print("â„¹ï¸  W&B ë¡œê¹…ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ëª¨ë¸ ë¡œë“œ (Config íŒŒì¼ ì§€ì›)
    if args.cfg:
        print(f"ğŸ”§ ì‚¬ìš©ì ì •ì˜ Configë¡œ ëª¨ë¸ ì´ˆê¸°í™”: {args.cfg}")
        print(f"ğŸ“ ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë”©: {args.model}")
        
        # Config íŒŒì¼ë¡œ ëª¨ë¸ êµ¬ì¡° ì´ˆê¸°í™”
        model = YOLO(args.cfg, task='detect')
        
        # ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ê°€ ìˆë‹¤ë©´ ë¡œë“œ (ì„ íƒì )
        if args.model and args.model != "yolo11n.pt" and os.path.exists(args.model):
            print(f"âœ… ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì ìš©: {args.model}")
            try:
                # ê°€ì¤‘ì¹˜ë§Œ ë¡œë“œ (êµ¬ì¡°ëŠ” configì—ì„œ ê°€ì ¸ì˜¨ ê²ƒì„ ìœ ì§€)
                checkpoint = torch.load(args.model, map_location='cpu')
                if 'model' in checkpoint:
                    weights = checkpoint['model']
                else:
                    weights = checkpoint
                    
                # í˜¸í™˜ ê°€ëŠ¥í•œ ë ˆì´ì–´ë§Œ ë¡œë“œ
                model.model.load_state_dict(weights, strict=False)
                print("âœ… ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì¼ë¶€ ì ìš© ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸  ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨ (config ëª¨ë¸ë¡œ ì§„í–‰): {e}")
        else:
            print("â„¹ï¸  Config íŒŒì¼ë¡œë§Œ ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤ (ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì—†ìŒ)")
    else:
        print(f"ğŸ“ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë”©: {args.model}")
        model = YOLO(args.model)
    
    # RGB-T ì…ë ¥ì„ ìœ„í•œ ëª¨ë¸ ìˆ˜ì • (6ì±„ë„)
    print("ğŸ”§ RGB-T 6ì±„ë„ ì…ë ¥ì„ ìœ„í•œ ëª¨ë¸ í™•ì¸ ë° ìˆ˜ì • ì¤‘...")
    
    modified_channels = False
    try:
        if hasattr(model.model, 'model') and len(model.model.model) > 0:
            first_layer = model.model.model[0]
            if hasattr(first_layer, 'conv'):
                first_conv = first_layer.conv
                current_channels = first_conv.in_channels
                
                print(f"â„¹ï¸  í˜„ì¬ ì…ë ¥ ì±„ë„ ìˆ˜: {current_channels}")
                
                if current_channels == 3:
                    print("ğŸ”„ 3ì±„ë„ â†’ 6ì±„ë„ ë³€í™˜ ì¤‘...")
                    new_conv = torch.nn.Conv2d(
                        in_channels=6,
                        out_channels=first_conv.out_channels,
                        kernel_size=first_conv.kernel_size,
                        stride=first_conv.stride,
                        padding=first_conv.padding,
                        bias=first_conv.bias is not None
                    )
                    
                    # ê¸°ì¡´ RGB ê°€ì¤‘ì¹˜ ë³µì‚¬ ë° í™•ì¥
                    with torch.no_grad():
                        new_conv.weight[:, :3] = first_conv.weight
                        new_conv.weight[:, 3:] = first_conv.weight  # Thermal ì±„ë„ì— RGB ê°€ì¤‘ì¹˜ ë³µì‚¬
                        if first_conv.bias is not None:
                            new_conv.bias = first_conv.bias
                    
                    model.model.model[0].conv = new_conv
                    modified_channels = True
                    print("âœ… ëª¨ë¸ì´ RGB-T 6ì±„ë„ ì…ë ¥ìœ¼ë¡œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    
                elif current_channels == 6:
                    print("âœ… ëª¨ë¸ì´ ì´ë¯¸ 6ì±„ë„ ì…ë ¥ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                else:
                    print(f"âš ï¸  ì˜ˆìƒì¹˜ ëª»í•œ ì…ë ¥ ì±„ë„ ìˆ˜: {current_channels}")
                
                # W&Bì— ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¡œê¹…
                if wandb_run:
                    wandb.log({
                        "model_input_channels": 6 if modified_channels or current_channels == 6 else current_channels,
                        "model_modification": "RGB-T_6_channel" if modified_channels else "no_modification",
                        "original_channels": current_channels,
                        "final_channels": 6 if modified_channels or current_channels == 6 else current_channels,
                        "channels_modified": modified_channels
                    })
            else:
                print("âš ï¸  ì²« ë²ˆì§¸ ë ˆì´ì–´ì—ì„œ conv ì†ì„±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print("âš ï¸  ëª¨ë¸ êµ¬ì¡°ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âš ï¸  ëª¨ë¸ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ê¸°ë³¸ ëª¨ë¸ êµ¬ì¡°ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.")
    
    # í›ˆë ¨ ì„¤ì • ì¶œë ¥
    print(f"""
ğŸ”¥ í›ˆë ¨ ì„¤ì •:
   ğŸ“Š ë°ì´í„°ì…‹: {args.data}
   ğŸ—ï¸  ëª¨ë¸ Config: {args.cfg if args.cfg else 'ê¸°ë³¸ ì„¤ì •'}
   ğŸƒ ì—í¬í¬: {args.epochs}
   ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {args.batch_size}
   ğŸ–¼ï¸  ì´ë¯¸ì§€ í¬ê¸°: {args.imgsz}x{args.imgsz}
   ğŸ’» ë””ë°”ì´ìŠ¤: {args.device} ({gpu_name})
   ğŸ‘· ì›Œì»¤ ìˆ˜: {args.workers}
   â° ì¡°ê¸° ì¢…ë£Œ patience: {args.patience}
   ğŸ’¾ ì €ì¥ ì£¼ê¸°: {args.save_period} ì—í¬í¬ë§ˆë‹¤
   ğŸ“ˆ W&B í”„ë¡œì íŠ¸: {args.wandb_project if not args.no_wandb else 'Disabled'}
    """)
    
    # í›ˆë ¨ ì‹œì‘
    print("ğŸš€ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    try:
        training_args = {
            'data': args.data,
            'epochs': args.epochs,
            'batch': args.batch_size,
            'imgsz': args.imgsz,
            'device': args.device,
            'project': args.project,
            'name': args.name,
            'workers': args.workers,
            'patience': args.patience,
            'save': True,
            'plots': True,
            'val': True,
            'verbose': True,
            'seed': 0,
            'deterministic': True,
            'resume': args.resume if args.resume else False,
            'save_period': args.save_period,
            
            # Optimizer settings
            'optimizer': 'AdamW',
            'lr0': 0.001,
            'lrf': 0.01,
            'momentum': 0.937,
            'weight_decay': 0.0005,
            'warmup_epochs': 3,
            'warmup_momentum': 0.8,
            'warmup_bias_lr': 0.1,
            
            # Loss settings
            'box': 7.5,
            'cls': 0.5,
            'dfl': 1.5,
            
            # Augmentation settings
            'hsv_h': 0.015,
            'hsv_s': 0.7,
            'hsv_v': 0.4,
            'degrees': 0.0,
            'translate': 0.1,
            'scale': 0.5,
            'shear': 0.0,
            'perspective': 0.0,
            'flipud': 0.0,
            'fliplr': 0.5,
            'mosaic': 1.0,
            'mixup': 0.0,
            'copy_paste': 0.0,
        }
        
        # Config íŒŒì¼ì´ ìˆëŠ” ê²½ìš° cfg ì¸ì ì¶”ê°€
        if args.cfg:
            training_args['cfg'] = args.cfg
        
        results = model.train(**training_args)
        
        # í›ˆë ¨ ì™„ë£Œ í›„ W&Bì— ìµœì¢… ê²°ê³¼ ë¡œê¹…
        if wandb_run and results:
            final_metrics = {
                "final/best_mAP50": getattr(results, 'results_dict', {}).get('metrics/mAP50(B)', 0),
                "final/best_mAP50-95": getattr(results, 'results_dict', {}).get('metrics/mAP50-95(B)', 0),
                "final/best_precision": getattr(results, 'results_dict', {}).get('metrics/precision(B)', 0),
                "final/best_recall": getattr(results, 'results_dict', {}).get('metrics/recall(B)', 0),
                "training_completed": True,
                "total_epochs": args.epochs,
                "used_custom_config": bool(args.cfg)
            }
            wandb.log(final_metrics)
            
            # ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì—…ë¡œë“œ (ì„ íƒì‚¬í•­)
            try:
                best_model_path = f"{args.project}/{args.name}/weights/best.pt"
                if os.path.exists(best_model_path):
                    wandb.save(best_model_path, base_path=args.project)
                    print("âœ… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ W&Bì— ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                    
                # Config íŒŒì¼ë„ í•¨ê»˜ ì—…ë¡œë“œ
                if args.cfg and os.path.exists(args.cfg):
                    wandb.save(args.cfg)
                    print("âœ… ì‚¬ìš©ëœ Config íŒŒì¼ì„ W&Bì— ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                print(f"âš ï¸  íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        print(f"âœ… í›ˆë ¨ ì™„ë£Œ! ìµœê³  ê²°ê³¼: {results}")
        
    except Exception as e:
        print(f"âŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if wandb_run:
            wandb.log({"training_error": str(e), "training_completed": False})
        raise
    
    finally:
        # W&B ì„¸ì…˜ ì¢…ë£Œ
        if wandb_run:
            wandb.finish()
            print("ğŸ“Š W&B ì„¸ì…˜ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return results

if __name__ == "__main__":
    main()